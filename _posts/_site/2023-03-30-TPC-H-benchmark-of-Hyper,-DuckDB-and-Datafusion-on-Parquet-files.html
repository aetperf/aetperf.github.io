<p><strong>Update</strong> Apr 14, 2023 - An issue has been opened on the DataFusion GitHub repository regarding its poor reported performance compared to DuckDB and Hyper in this specific case: <a href="https://github.com/apache/arrow-datafusion/issues/5942">#5942</a>. While there may be multiple factors contributing to this unexpected behavior, I might have used the API in a sub-optimal way. I will continue to update the post with new findings.</p>

<p align="center">
  <img width="300" src="/img/2023-03-30_01/parquet_logo.jpg" alt="parquet" />
</p>

<p>In this blog post, we focus on directly querying Parquet files using three different SQL engines, and more specifically their Python API:</p>
<ul>
  <li><a href="https://help.tableau.com/current/api/hyper_api/en-us/index.html">Tableau Hyper</a> / Proprietary License</li>
  <li><a href="https://duckdb.org/">DuckDB</a> / MIT License</li>
  <li><a href="https://arrow.apache.org/datafusion/">Apache Arrow DataFusion</a> / Apache License 2.0</li>
</ul>

<p>The <a href="https://www.tpc.org/tpch/">TPC-H</a> benchmark is a widely-used measure of such systems’ performance, consisting of a set of queries that have broad industry-wide relevance. We executed the TPC-H benchmark on a laptop and present our findings on the performance and capabilities of each engine on Parquet files.</p>

<h2 id="tpc-h-sf100">TPC-H SF100</h2>

<p>The TPC-H data used in this benchmark is generated using the DuckDB <a href="https://duckdb.org/docs/extensions/overview.html#all-available-extensions">TPC-H extension</a> and saved into Parquet files with default compression “snappy” and row group size 122880. The benchmark comprises 8 tables, with a scale factor of 100 used for data generation. Each table is stored in a separate Parquet file.</p>

<p>Here’s a brief overview of each table:</p>

<table>
  <thead>
    <tr>
      <th>Table name</th>
      <th style="text-align: right">Row count</th>
      <th style="text-align: right">Parquet file size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>region</td>
      <td style="text-align: right">5</td>
      <td style="text-align: right">1.0 kB</td>
    </tr>
    <tr>
      <td>nation</td>
      <td style="text-align: right">25</td>
      <td style="text-align: right">2.2 kB</td>
    </tr>
    <tr>
      <td>supplier</td>
      <td style="text-align: right">1 000 000</td>
      <td style="text-align: right">80.4 MB</td>
    </tr>
    <tr>
      <td>customer</td>
      <td style="text-align: right">15 000 000</td>
      <td style="text-align: right">1.3 GB</td>
    </tr>
    <tr>
      <td>part</td>
      <td style="text-align: right">20 000 000</td>
      <td style="text-align: right">695.4 MB</td>
    </tr>
    <tr>
      <td>partsupp</td>
      <td style="text-align: right">80 000 000</td>
      <td style="text-align: right">4.5 GB</td>
    </tr>
    <tr>
      <td>orders</td>
      <td style="text-align: right">150 000 000</td>
      <td style="text-align: right">6.8 GB</td>
    </tr>
    <tr>
      <td>lineitem</td>
      <td style="text-align: right">600 037 902</td>
      <td style="text-align: right">27.1 GB</td>
    </tr>
  </tbody>
</table>

<p>The <code class="language-plaintext highlighter-rouge">lineitem</code> table is the largest, with over 600 million rows and a file size of 27.1 GB.</p>

<h2 id="tpc-h-queries">TPC-H queries</h2>

<p>There are 22 queries, specified in the TPC-H documentation; they may vary a little bit depending on each implemnetation. The queries used in this post can be found <a href="https://raw.githubusercontent.com/aetperf/tpch/main/queries/duckdb/queries_native.sql">here</a> on Github. Here is the first one, for example:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span>
    <span class="c1">--Query01</span>
    <span class="n">l_returnflag</span><span class="p">,</span>
    <span class="n">l_linestatus</span><span class="p">,</span>
    <span class="k">SUM</span><span class="p">(</span><span class="n">l_quantity</span><span class="p">)</span> <span class="k">AS</span> <span class="n">sum_qty</span><span class="p">,</span>
    <span class="k">SUM</span><span class="p">(</span><span class="n">l_extendedprice</span><span class="p">)</span> <span class="k">AS</span> <span class="n">sum_base_price</span><span class="p">,</span>
    <span class="k">SUM</span><span class="p">(</span><span class="n">l_extendedprice</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l_discount</span><span class="p">))</span> <span class="k">AS</span> <span class="n">sum_disc_price</span><span class="p">,</span>
    <span class="k">SUM</span><span class="p">(</span><span class="n">l_extendedprice</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">l_discount</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">l_tax</span><span class="p">))</span> <span class="k">AS</span> <span class="n">sum_charge</span><span class="p">,</span>
    <span class="k">AVG</span><span class="p">(</span><span class="n">l_quantity</span><span class="p">)</span> <span class="k">AS</span> <span class="n">avg_qty</span><span class="p">,</span>
    <span class="k">AVG</span><span class="p">(</span><span class="n">l_extendedprice</span><span class="p">)</span> <span class="k">AS</span> <span class="n">avg_price</span><span class="p">,</span>
    <span class="k">AVG</span><span class="p">(</span><span class="n">l_discount</span><span class="p">)</span> <span class="k">AS</span> <span class="n">avg_disc</span><span class="p">,</span>
    <span class="k">COUNT</span><span class="p">(</span><span class="o">*</span><span class="p">)</span> <span class="k">AS</span> <span class="n">count_order</span>
<span class="k">FROM</span>
    <span class="n">lineitem</span>
<span class="k">WHERE</span>
    <span class="n">l_shipdate</span> <span class="o">&lt;=</span> <span class="k">CAST</span><span class="p">(</span><span class="s1">'1998-09-02'</span> <span class="k">AS</span> <span class="nb">date</span><span class="p">)</span>
<span class="k">GROUP</span> <span class="k">BY</span>
    <span class="n">l_returnflag</span><span class="p">,</span>
    <span class="n">l_linestatus</span>
<span class="k">ORDER</span> <span class="k">BY</span>
    <span class="n">l_returnflag</span><span class="p">,</span>
    <span class="n">l_linestatus</span><span class="p">;</span>
</code></pre></div></div>

<h2 id="system-information">System information</h2>

<p>The queries are executed on a laptop with the following features:</p>

<p>CPU : 12th Gen Intel© Core™ i9-12900H, 10 cores<br />
RAM : 32 GB<br />
OS : Linux mint 21.1, based on Ubuntu 22.04<br />
Data disk : Samsung SSD 980 PRO 1TB</p>

<p>Package versions:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Python          : 3.11.0 | packaged by conda-forge  
DuckDB          : 0.7.2-dev982  
TableauHyperAPI : 0.0.16638  
Datafusion      : 20.0.0  
</code></pre></div></div>

<h3 id="parquet-files-attachment-and-specific-parameters">Parquet files attachment and specific parameters</h3>

<p>The attachment process is chosen in a way that the data is not scanned, being almost instantaneous.</p>

<h4 id="hyper">Hyper</h4>

<p>We used a specific parameter for the Hyper engine, following a discussion with the Tableau Hyper team on <a href="tableau-datadev.slack.com">Slack</a>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">with</span> <span class="nc">HyperProcess</span><span class="p">(</span>
    <span class="n">telemetry</span><span class="o">=</span><span class="n">Telemetry</span><span class="p">.</span><span class="n">DO_NOT_SEND_USAGE_DATA_TO_TABLEAU</span><span class="p">,</span>
    <span class="n">parameters</span><span class="o">=</span><span class="nf">dict</span><span class="p">({(</span><span class="sh">"</span><span class="s">external_table_sample_size_factor</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">0.005</span><span class="sh">"</span><span class="p">)}),</span>
<span class="p">)</span> <span class="k">as</span> <span class="n">hyper</span><span class="p">:</span>
</code></pre></div></div>

<p>Without this setting, query 9 would crash with an out-of-memory error. The Parquet files are attached as temporary external tables, e.g.:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">TEMPORARY</span> <span class="k">EXTERNAL</span> <span class="k">TABLE</span> <span class="n">region</span> <span class="k">FOR</span> <span class="s1">'./region.parquet'</span>
</code></pre></div></div>

<h4 id="duckdb">DuckDB</h4>

<p>The default configuration is used. The Parquet files are attached as views:</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">CREATE</span> <span class="k">VIEW</span> <span class="n">region</span> <span class="k">AS</span> <span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">read_parquet</span><span class="p">(</span><span class="s1">'./region.parquet'</span><span class="p">)</span>
</code></pre></div></div>
<p>Query 21 is crashing with a <em>cannot allocate memory</em> error.</p>

<h4 id="datafusion">DataFusion</h4>

<p>We tried a few parameters such as <code class="language-plaintext highlighter-rouge">enable_page_index</code>, <code class="language-plaintext highlighter-rouge">pushdown_filters</code>, <code class="language-plaintext highlighter-rouge">reorder_filters</code> but without success… The default configuration seems to be limited and we did not figure out how to adjust the settings. Queries 7, 17, 18 and 21 are crashing.</p>

<p>The Parquet files are attached using the Python API:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ctx</span> <span class="o">=</span> <span class="n">datafusion</span><span class="p">.</span><span class="nc">SessionContext</span><span class="p">()</span>
<span class="n">ctx</span><span class="p">.</span><span class="nf">register_parquet</span><span class="p">(</span><span class="sh">'</span><span class="s">region</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">./region.parquet</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="results">Results</h2>

<p>Only the Hyper engine succeed in running all the queries, in a total elapsed time of <strong>63.90 s</strong>, with the connection setup, loop on files etc… Note that this time can be significantly improved by using the respective native storage format of the DuckDB or Hyper engines.</p>

<p>We did not include fetch time in the elapsed time, except for Datafusion. So for DuckDB and Hyper, we only measure the query execution time. The data is fetched in a second step in order to check the number of returned rows.</p>

<ul>
  <li>DuckDB:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># start timer
</span><span class="n">conn</span><span class="p">.</span><span class="nf">execute</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="c1"># stop timer
</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">df</span><span class="p">()</span>
<span class="n">n_returned_rows</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre></div></div>

<ul>
  <li>Hyper</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># start timer
</span><span class="n">result</span> <span class="o">=</span> <span class="n">conn</span><span class="p">.</span><span class="nf">execute_query</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="c1"># stop timer
</span>
<span class="n">n_returned_rows</span> <span class="o">=</span> <span class="mi">0</span>
<span class="k">while</span> <span class="n">result</span><span class="p">.</span><span class="nf">next_row</span><span class="p">():</span>
    <span class="n">n_returned_rows</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">result</span><span class="p">.</span><span class="nf">close</span><span class="p">()</span>
</code></pre></div></div>

<ul>
  <li>Datafusion</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># start timer
</span><span class="n">result</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="nf">sql</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">result</span><span class="p">.</span><span class="nf">collect</span><span class="p">()</span>
<span class="c1"># stop timer
</span>
<span class="n">n_returned_rows</span> <span class="o">=</span> <span class="mi">0</span> 
<span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">item</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
    <span class="n">n_returned_rows</span> <span class="o">+=</span> <span class="n">item</span><span class="p">.</span><span class="n">num_rows</span>
</code></pre></div></div>

<p>Overall, in this test, Datafusion is behind, while Hyper is a bit more efficient than DuckDB, specifically on some queries.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: right">query</th>
      <th style="text-align: right">Hyper (s)</th>
      <th style="text-align: right">DuckDB (s)</th>
      <th style="text-align: right">Datafusion (s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: right">1</td>
      <td style="text-align: right">3.626</td>
      <td style="text-align: right">3.793</td>
      <td style="text-align: right">81.668</td>
    </tr>
    <tr>
      <td style="text-align: right">2</td>
      <td style="text-align: right">1.006</td>
      <td style="text-align: right">0.849</td>
      <td style="text-align: right">13.944</td>
    </tr>
    <tr>
      <td style="text-align: right">3</td>
      <td style="text-align: right">2.619</td>
      <td style="text-align: right">2.854</td>
      <td style="text-align: right">39.433</td>
    </tr>
    <tr>
      <td style="text-align: right">4</td>
      <td style="text-align: right">1.896</td>
      <td style="text-align: right">5.010</td>
      <td style="text-align: right">30.512</td>
    </tr>
    <tr>
      <td style="text-align: right">5</td>
      <td style="text-align: right">3.521</td>
      <td style="text-align: right">3.131</td>
      <td style="text-align: right">51.143</td>
    </tr>
    <tr>
      <td style="text-align: right">6</td>
      <td style="text-align: right">1.221</td>
      <td style="text-align: right">2.162</td>
      <td style="text-align: right">19.821</td>
    </tr>
    <tr>
      <td style="text-align: right">7</td>
      <td style="text-align: right">2.660</td>
      <td style="text-align: right">6.300</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">8</td>
      <td style="text-align: right">2.151</td>
      <td style="text-align: right">3.021</td>
      <td style="text-align: right">49.717</td>
    </tr>
    <tr>
      <td style="text-align: right">9</td>
      <td style="text-align: right">6.085</td>
      <td style="text-align: right">10.374</td>
      <td style="text-align: right">65.606</td>
    </tr>
    <tr>
      <td style="text-align: right">10</td>
      <td style="text-align: right">2.820</td>
      <td style="text-align: right">3.825</td>
      <td style="text-align: right">41.010</td>
    </tr>
    <tr>
      <td style="text-align: right">11</td>
      <td style="text-align: right">0.360</td>
      <td style="text-align: right">0.416</td>
      <td style="text-align: right">14.066</td>
    </tr>
    <tr>
      <td style="text-align: right">12</td>
      <td style="text-align: right">1.991</td>
      <td style="text-align: right">2.773</td>
      <td style="text-align: right">38.985</td>
    </tr>
    <tr>
      <td style="text-align: right">13</td>
      <td style="text-align: right">7.303</td>
      <td style="text-align: right">4.588</td>
      <td style="text-align: right">56.703</td>
    </tr>
    <tr>
      <td style="text-align: right">14</td>
      <td style="text-align: right">1.402</td>
      <td style="text-align: right">1.936</td>
      <td style="text-align: right">18.684</td>
    </tr>
    <tr>
      <td style="text-align: right">15</td>
      <td style="text-align: right">1.634</td>
      <td style="text-align: right">4.254</td>
      <td style="text-align: right">27.640</td>
    </tr>
    <tr>
      <td style="text-align: right">16</td>
      <td style="text-align: right">0.882</td>
      <td style="text-align: right">0.848</td>
      <td style="text-align: right">6.699</td>
    </tr>
    <tr>
      <td style="text-align: right">17</td>
      <td style="text-align: right">1.728</td>
      <td style="text-align: right">12.502</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">18</td>
      <td style="text-align: right">5.917</td>
      <td style="text-align: right">15.003</td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">19</td>
      <td style="text-align: right">3.250</td>
      <td style="text-align: right">4.018</td>
      <td style="text-align: right">42.300</td>
    </tr>
    <tr>
      <td style="text-align: right">20</td>
      <td style="text-align: right">1.124</td>
      <td style="text-align: right">4.919</td>
      <td style="text-align: right">80.375</td>
    </tr>
    <tr>
      <td style="text-align: right">21</td>
      <td style="text-align: right">4.430</td>
      <td style="text-align: right"> </td>
      <td style="text-align: right"> </td>
    </tr>
    <tr>
      <td style="text-align: right">22</td>
      <td style="text-align: right">0.995</td>
      <td style="text-align: right">1.938</td>
      <td style="text-align: right">11.485</td>
    </tr>
    <tr>
      <td style="text-align: right">Sum</td>
      <td style="text-align: right">58.631</td>
      <td style="text-align: right">94.523</td>
      <td style="text-align: right">689.797</td>
    </tr>
  </tbody>
</table>

<p>At the bottom of this table, we display the sum of the querying time, ignoring the failing queries.</p>

<h3 id="all-three-engines">All three engines</h3>

<p align="center">
  <img width="1200" src="/img/2023-03-30_01/figure_01.png" alt="all_engines" />
</p>

<h3 id="duckdb-vs-hyper">DuckDB vs Hyper</h3>

<p align="center">
  <img width="1200" src="/img/2023-03-30_01/figure_02.png" alt="duckdb_vs_hyper" />
</p>

<h2 id="conclusion">Conclusion</h2>

<p>In this blog post, we conducted the TPC-H benchmark using three different SQL engines: Tableau Hyper, DuckDB, and Apache Arrow DataFusion, for querying Parquet files. The benchmark comprised 22 queries executed on 8 tables, with a scale factor of 100 used for data generation.</p>

<p>With the default settings, it seems that Datafusion may not be the most suitable option for the specific use case mentioned due to its slow performance and tendency to crash. On the other hand, the Hyper engine was found to be faster than the DuckDB engine. But ultimately, the choice of database engine depends on a variety of factors such as the license, the size and complexity of the dataset, the nature of the queries, the available hardware resources…</p>

<p>Overall, the benchmark demonstrated the potential of these SQL engines for handling a significant amount of data stored in Parquet files.</p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://aetperf-github-io-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

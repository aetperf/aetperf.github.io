<p align="center">
  <img width="600" src="/img/2019-08-09_01/moebius.jpg" alt="Moebius" />
</p>

<p>Since we are big users of <em>scikit-learn</em> and <em>XGBoost</em>, we wanted to try a package that would automate the process of building a machine learning model with these tools. Here is the introduction to <em>auto-sklearn</em> from its <a href="https://automl.github.io/auto-sklearn/master/index.html">github.io</a> website:</p>

<blockquote>
  <p><em>auto-sklearn</em> is an automated machine learning toolkit and a drop-in replacement for a <em>scikit-learn</em> estimator. It leverages recent advantages in Bayesian optimization, meta-learning and ensemble construction.</p>
</blockquote>

<p>Here is the wikipedia definition of <a href="https://en.wikipedia.org/wiki/Automated_machine_learning">AutoML</a>:</p>

<blockquote>
  <p>Automated machine learning (AutoML) is the process of automating end-to-end the process of applying machine learning to real-world problems. In a typical machine learning application, practitioners have a dataset consisting of input data points to train on. The raw data itself may not be in a form that all algorithms may be applicable to it out of the box. An expert may have to apply the appropriate data pre-processing, feature engineering, feature extraction, and feature selection methods that make the dataset amenable for machine learning. Following those preprocessing steps, practitioners must then perform algorithm selection and hyperparameter optimization to maximize the predictive performance of their final machine learning model. As many of these steps are often beyond the abilities of non-experts, AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning.</p>
</blockquote>

<p>The theory behind <em>auto-sklearn</em> package is presented in the paper published at <a href="http://papers.nips.cc/paper/5872-efficient-and-robust-automated-machine-learning.pdf">NIPS2015</a> (to be honest, I did not read the article because I just wanted to give <code class="language-plaintext highlighter-rouge">auto-sklearn</code> a very quick try with some very basic examples).</p>

<p>Here are the main features of the API. You can:</p>
<ul>
  <li>set time and memory limits</li>
  <li>restrict the searchspace by selecting or excluding some preprocessing methods or some estimators</li>
  <li>specify some resampling strategies (e.g. 5-fold cv)</li>
  <li>perform some parallel computation with the SMAC algorithm (sequential model-based algorithm configuration) that stores some data on a shared file system</li>
  <li>save your model as you would do with <em>scikit-learn</em> (<code class="language-plaintext highlighter-rouge">pickle</code>)</li>
</ul>

<p>We are going to try it on two toy datasets for <strong>classification</strong> algorithms:</p>
<ul>
  <li>hand-written digits</li>
  <li>breast cancer</li>
</ul>

<h2 id="installation">Installation</h2>

<p>At first we had a <em>Segmentation fault</em> when running the model. We found some useful information on <a href="https://github.com/automl/auto-sklearn/issues/688">github</a>, and here are the steps performed to install <code class="language-plaintext highlighter-rouge">auto-sklearn</code> (0.5.2) on an Ubuntu 18.04 OS, in a python 3.7 <code class="language-plaintext highlighter-rouge">conda</code> environment:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nv">$ </span>conda create <span class="nt">-n</span> autosklearn <span class="nv">python</span><span class="o">=</span>3.7
<span class="nv">$ </span><span class="nb">source </span>activate autosklearn
<span class="o">(</span>autosklearn<span class="o">)</span> <span class="nv">$ </span>conda <span class="nb">install</span> <span class="nt">-c</span> conda-forge <span class="s1">'swig&lt;4'</span>
<span class="o">(</span>autosklearn<span class="o">)</span> <span class="nv">$ </span>conda <span class="nb">install </span>gxx_linux-64 gcc_linux-64
<span class="o">(</span>autosklearn<span class="o">)</span> <span class="nv">$ </span>curl https://raw.githubusercontent.com/automl/auto-sklearn/master/requirements.txt | xargs <span class="nt">-n</span> 1 <span class="nt">-L</span> 1 pip <span class="nb">install</span>
<span class="o">(</span>autosklearn<span class="o">)</span> <span class="nv">$ </span>pip <span class="nb">install</span> <span class="s1">'pyrfr&gt;=0.8'</span>
<span class="o">(</span>autosklearn<span class="o">)</span> <span class="nv">$ </span>pip <span class="nb">install </span>auto-sklearn
</code></pre></div></div>

<p>Note that the <em>scikit-learn</em> version associated with <em>auto-sklearn</em> is 0.19.2 (latest is 0.21.3).</p>

<h2 id="first-data-set">First data set</h2>

<p><a href="https://archive.ics.uci.edu/ml/datasets/optical+recognition+of+handwritten+digits">This</a> is a description of the UCI ML hand-written digits dataset: each datapoint is a 8x8 image of a digit. However we only have a subset (copy of the test set) included in <em>scikit-learn</em>. So we can say that it is rather small (table from <em>scikit-lean</em>’s documentation):</p>

<table>
  <thead>
    <tr>
      <th>Characteristics</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Classes</td>
      <td style="text-align: center"> 10</td>
    </tr>
    <tr>
      <td>Samples per class</td>
      <td style="text-align: center">~180</td>
    </tr>
    <tr>
      <td>Samples total</td>
      <td style="text-align: center">1797</td>
    </tr>
    <tr>
      <td>Dimensionality</td>
      <td style="text-align: center">64</td>
    </tr>
    <tr>
      <td>Features</td>
      <td style="text-align: center">integers 0-16</td>
    </tr>
  </tbody>
</table>

<h3 id="basic-algorithm">Basic algorithm</h3>

<p>Let’s run a very simple algorithm (taken from this <em>scikit-learn</em> <a href="https://scikit-learn.org/stable/auto_examples/classification/plot_digits_classification.html#sphx-glr-auto-examples-classification-plot-digits-classification-py">example</a>) in order to compare elapsed time and accuracy with <em>auto-sklearn</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="o">%%</span><span class="n">time</span>
<span class="kn">import</span> <span class="n">sklearn.datasets</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="n">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="nf">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">model_selection</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="c1"># Create a classifier: a support vector classifier
</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">svm</span><span class="p">.</span><span class="nc">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="n">classifier</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">classifier</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy score: </span><span class="si">{</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>Accuracy score: 0.991<br />
CPU times: user 262 ms, sys: 0 ns, total: 262 ms<br />
Wall time: 316 ms</p>

<h3 id="auto-sklearn">Auto-sklearn</h3>

<p>This is the first python script given in the <em>auto-sklearn</em> <a href="https://automl.github.io/auto-sklearn/master/index.html#example">documentation</a>:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">autosklearn.classification</span>
<span class="kn">import</span> <span class="n">sklearn.model_selection</span>
<span class="kn">import</span> <span class="n">sklearn.datasets</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">datasets</span><span class="p">.</span><span class="nf">load_digits</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">sklearn</span><span class="p">.</span><span class="n">model_selection</span><span class="p">.</span><span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="p">.</span><span class="n">classification</span><span class="p">.</span><span class="nc">AutoSklearnClassifier</span><span class="p">()</span>
<span class="n">automl</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_hat</span> <span class="o">=</span> <span class="n">automl</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy score: </span><span class="si">{</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>We just made one small change; since we want to make sure to use several cores,  we instanciate the <code class="language-plaintext highlighter-rouge">autosklearn</code> model with this argument:</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="p">.</span><span class="n">classification</span><span class="p">.</span><span class="nc">AutoSklearnClassifier</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div>
<p>And let’s run it……………………………………………………………………………………………………</p>

<p>Accuracy score: 0.993<br />
14020,06s user 3161,23s system 477% cpu 1:00:01,78 total</p>

<p>The first remark is that it takes a very long time to run, about 53 minutes. However, we did not set any constraint on the algorithms to try, or set a time limit.</p>

<p>The accuracy score is not so bad: <em>0.993</em>! The <em>auto-sklearn</em> algorithm did not see the test set at all, so there is no data leakage.</p>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th style="text-align: right">Elapsed time (s)</th>
      <th style="text-align: right">Accuracy score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Basic</td>
      <td style="text-align: right"> 0.32</td>
      <td style="text-align: right"> 0.991</td>
    </tr>
    <tr>
      <td><em>auto-sklearn</em></td>
      <td style="text-align: right"> 3601.78</td>
      <td style="text-align: right">0.993</td>
    </tr>
  </tbody>
</table>

<h2 id="second-data-set">Second data set</h2>

<p><a href="https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)">This</a> is a description of the Breast Cancer Wisconsin (Diagnostic) Data Set: each datapoint is a collection of geometric measurements of a breast mass computed from a digitized image. Here is description table from <em>scikit-lean</em>’s documentation:</p>

<table>
  <thead>
    <tr>
      <th>Characteristics</th>
      <th style="text-align: center"> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Classes</td>
      <td style="text-align: center"> 2</td>
    </tr>
    <tr>
      <td>Samples per class</td>
      <td style="text-align: center">212(M),357(B)</td>
    </tr>
    <tr>
      <td>Samples total</td>
      <td style="text-align: center">569</td>
    </tr>
    <tr>
      <td>Dimensionality</td>
      <td style="text-align: center">30</td>
    </tr>
    <tr>
      <td>Features</td>
      <td style="text-align: center">real, positive</td>
    </tr>
  </tbody>
</table>

<p>M: malignant<br />
B: benign</p>

<p>Again, this is a very small dataset.</p>

<h3 id="basic-algorithm-1">Basic algorithm</h3>

<p>We run a logistic regression classifier with default settings, and without any preprocessing except scaling:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">RobustScaler</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="n">RS</span> <span class="o">=</span> <span class="mi">124</span>  <span class="c1"># random seed
</span>
<span class="n">data</span> <span class="o">=</span> <span class="nf">load_breast_cancer</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">target</span>
<span class="n">df</span><span class="p">.</span><span class="n">target</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">df</span><span class="p">.</span><span class="n">target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>

<span class="n">rsc</span> <span class="o">=</span> <span class="nc">RobustScaler</span><span class="p">()</span>
<span class="n">lrc</span> <span class="o">=</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="nf">make_pipeline</span><span class="p">(</span><span class="n">rsc</span><span class="p">,</span> <span class="n">lrc</span><span class="p">)</span>
<span class="n">pipeline</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">predictions</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy score: </span><span class="si">{</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Balanced accuracy score: </span><span class="si">{</span><span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>Accuracy score:  0.971<br />
Balanced accuracy score:  0.964<br />
python breast_cancer_01.py  0,74s user 0,27s system 167% cpu 0,603 total</p>

<p>We compute the balanced accuracy score since the classes are a little imbalanced. We could not find <code class="language-plaintext highlighter-rouge">sklearn.metrics.balanced_accuracy_score</code> in the 0.19.2 release, so used <code class="language-plaintext highlighter-rouge">roc_auc_score</code> instead, which is equivalent in the case of a binary classification.</p>

<h3 id="auto-sklearn-1">Auto-sklearn</h3>

<p>The <em>auto-sklearn</em> code is very similar to the previous one:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="n">autosklearn.classification</span>
<span class="kn">import</span> <span class="n">sklearn.datasets</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">roc_auc_score</span>

<span class="n">RS</span> <span class="o">=</span> <span class="mi">124</span>  <span class="c1"># random seed
</span>
<span class="n">data</span> <span class="o">=</span> <span class="nf">load_breast_cancer</span><span class="p">()</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="p">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">target</span>
<span class="n">df</span><span class="p">.</span><span class="n">target</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">df</span><span class="p">.</span><span class="n">target</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">target</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>

<span class="n">automl</span> <span class="o">=</span> <span class="n">autosklearn</span><span class="p">.</span><span class="n">classification</span><span class="p">.</span><span class="nc">AutoSklearnClassifier</span><span class="p">(</span><span class="n">n_jobs</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">automl</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">predictions</span> <span class="o">=</span> <span class="n">automl</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Accuracy score : </span><span class="si">{</span><span class="nf">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Balanced accuracy score : </span><span class="si">{</span><span class="nf">roc_auc_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="si">:</span> <span class="mf">6.3</span><span class="n">f</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>python autosklearn_02.py  15038,88s user 923,99s system 443% cpu 1:00:01,35 total<br />
Accuracy score :  0.947<br />
Balanced accuracy score :  0.936</p>

<table>
  <thead>
    <tr>
      <th>Algorithm</th>
      <th style="text-align: right">Elapsed time (s)</th>
      <th style="text-align: right">Balanced accuracy score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Basic</td>
      <td style="text-align: right"> 0.60</td>
      <td style="text-align: right"> 0.964</td>
    </tr>
    <tr>
      <td><em>auto-sklearn</em></td>
      <td style="text-align: right"> 3601.35</td>
      <td style="text-align: right">0.936</td>
    </tr>
  </tbody>
</table>

<h2 id="final-thoughts">Final thoughts</h2>

<p>It it a little weird that the elapsed time for each dataset is about 1 hour with <em>auto-sklearn</em>, maybe there is a default time limit for small datasets?</p>

<p>Anyway, in both case <em>auto-sklearn</em> gives some decent accuracy results, but with a very large amount of computation with respect to the problem given.</p>

<p>We should try some other examples and maybe reduce the search space and give some hints to the algorithms…</p>

<p>Although we are often using some automatic hyperparameter tuning tools, it seems that automating the end-to-end process is not very efficient, energy-wise :) However, we are still interested in trying <em>auto-sklearn</em> on some other test cases and some other AutoML packages as well.</p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://aetperf-github-io-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

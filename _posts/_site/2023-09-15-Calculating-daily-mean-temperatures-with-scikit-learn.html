<p>The goal is of this post is to predict the daily mean air temperature TAVG from the following climate data variables: maximum and minimum daily temperatures and daily precipitation, using Python and some machine learning techniques available in <a href="https://scikit-learn.org/stable/">scikit-learn</a>.</p>

<p>Our dataset comes from the <a href="https://www.ncei.noaa.gov/cdo-web/search">Climate Data Online Search</a> provided by the National Centers for Environmental Information (NCEI), a U.S. government agency that manages an extensive archive of atmospheric, coastal, geophysical, and oceanic data. Specifically, they have gathered data from the Lyon station, located at the Saint-Exupéry airport, spanning from 1920 to the present day.</p>

<p>The key variables we’ll be working with are:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>PRCP = Precipitation (tenths of mm)
TMAX = Maximum temperature (tenths of degrees C)
TMIN = Minimum temperature (tenths of degrees C)
TAVG = Average temperature (tenths of degrees C)
  [Note that TAVG from source 'S' corresponds
   to an average for the period ending at
   2400 UTC rather than local midnight]
</code></pre></div></div>

<p>The description above can be found in the dataset <a href="https://www.ncei.noaa.gov/pub/data/ghcn/daily/readme.txt">documentation</a>.</p>

<p>However, a significant portion of the TAVG data is missing. The dataset has 37614 rows and 5 columns: DATE, PRCP, TAVG, TMAX and TMIN, and TAVG is missing for more that half of the time range:</p>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/missingno.png" alt="missingno" />
</p>

<p>Our initial strategy involves calculating TAVG as the arithmetic mean of TMAX and TMIN, but this is not the best option. Here is a excerpt from the dissertation abstract by Jase Bernhardt [1] about this traditional approach:</p>

<blockquote>
  <p>Traditionally, daily average temperature is computed by taking the mean of two values- the maximum temperature over a 24-hour period and the minimum temperature over the same period. These data form the basis for numerous studies of long-term climatologies (e.g. 30-year normals) and recent temperature trends and changes. However, many first-order weather stations (e.g. airports) also record hourly temperature data. Using an average of the 24 hourly temperature readings to compute daily average temperature should provide a more precise and representative estimate of a given day’s temperature. These two methods of daily temperature averaging ([Tmax + Tmin]/2, average of 24 hourly temperature values) were computed and mapped for all first-order weather stations across the United States for the 30-year period 1981-2010. This analysis indicates a statistically significant difference between the two methods, as well as an overestimation of temperature by the traditional method ([Tmax + Tmin]/2), particularly in southern and coastal portions of the Continental U.S. The likely explanation for the long-term difference between the two methods is the underlying assumption of the twice-daily method that the diurnal curve of temperature follows a symmetrical pattern.</p>
</blockquote>

<p>In this post, we’ll go through feature engineering: extract temporal features, compute the diurnal temperature range (DTR), consider daylight duration, and calculate the deltas of TMIN and TMAX with the previous and next days. We’ll evaluate the performance of different models, including:</p>

<ul>
  <li>Baseline Model: Arithmetic mean of TMIN and TMAX</li>
  <li>Ridge Regression</li>
  <li>Decision Tree Regressor</li>
  <li>Random Forest Regressor</li>
  <li>Histogram-based Gradient Boosting Regressor</li>
</ul>

<p>We’ll assess these models using mean absolute error (MAE) and root mean squared error (RMSE) to determine which one provides the most accurate predictions for TAVG, with the baseline being the arithmetic mean of TMIN and TMAX.</p>

<h2 id="imports">Imports</h2>

<p>Let’s start by gathering the tools we need in the following:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">warnings</span>

<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msno</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">from</span> <span class="n">astral</span> <span class="kn">import</span> <span class="n">Observer</span>
<span class="kn">from</span> <span class="n">astral.sun</span> <span class="kn">import</span> <span class="n">daylight</span>
<span class="kn">from</span> <span class="n">optuna</span> <span class="kn">import</span> <span class="n">create_study</span>
<span class="kn">from</span> <span class="n">optuna.exceptions</span> <span class="kn">import</span> <span class="n">ExperimentalWarning</span>
<span class="kn">from</span> <span class="n">optuna.samplers</span> <span class="kn">import</span> <span class="n">NSGAIISampler</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">HistGradientBoostingRegressor</span><span class="p">,</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_absolute_error</span><span class="p">,</span> <span class="n">mean_squared_error</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="n">sklego.preprocessing</span> <span class="kn">import</span> <span class="n">RepeatingBasisFunction</span>

<span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">"</span><span class="s">ignore</span><span class="sh">"</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="n">ExperimentalWarning</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">style</span><span class="p">.</span><span class="nf">use</span><span class="p">(</span><span class="sh">"</span><span class="s">fivethirtyeight</span><span class="sh">"</span><span class="p">)</span>

<span class="n">temperature_fp</span> <span class="o">=</span> <span class="sh">"</span><span class="s">./3441363.csv</span><span class="sh">"</span>
<span class="n">RS</span> <span class="o">=</span> <span class="mi">124</span>  <span class="c1"># random seed
</span><span class="n">FS</span> <span class="o">=</span> <span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>  <span class="c1"># figure size
</span></code></pre></div></div>

<p>OS and package versions:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Python version       : 3.11.5  
OS                   : Linux  
Machine              : x86_64  
matplotlib           : 3.7.2  
numpy                : 1.24.4  
pandas               : 2.1.0  
astral               : 3.2  
optuna               : 3.3.0  
sklearn              : 1.3.0  
</code></pre></div></div>

<h2 id="load-the-data">Load the data</h2>

<p>Let’s start by loading the data we’ll be working with, downloaded as a CSV file:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="n">temperature_fp</span><span class="p">)</span>  <span class="c1"># Load the dataset and select the relevant columns
</span><span class="n">station</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">STATION</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">NAME</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">LATITUDE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">LONGITUDE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">ELEVATION</span><span class="sh">"</span><span class="p">]].</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">PRCP</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">]].</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">"</span><span class="s">all</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># Convert the 'DATE' column to a datetime format and set it as the index
</span><span class="n">df</span><span class="p">.</span><span class="n">DATE</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">DATE</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">asfreq</span><span class="p">(</span><span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">sort_index</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PRCP</th>
      <th>TAVG</th>
      <th>TMIN</th>
      <th>TMAX</th>
    </tr>
    <tr>
      <th>DATE</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1920-09-01</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>8.8</td>
      <td>19.7</td>
    </tr>
    <tr>
      <th>1920-09-02</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>9.1</td>
      <td>20.1</td>
    </tr>
    <tr>
      <th>1920-09-03</th>
      <td>1.5</td>
      <td>NaN</td>
      <td>9.3</td>
      <td>16.8</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now, let’s take a closer look at the dataset’s dimensions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(37617, 4)
</code></pre></div></div>

<p>This corresponds to approximately 103 years of daily data. We also got some information about the weather station:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">station</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>STATION              FR069029001
NAME         LYON ST EXUPERY, FR
LATITUDE                 45.7264
LONGITUDE                 5.0778
ELEVATION                  235.0
Name: 0, dtype: object
</code></pre></div></div>

<p>It’s worth noting a peculiar aspect of the data: the daily mean temperature can sometimes be slightly smaller than the daily minimum temperature:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span> <span class="o">&lt;</span> <span class="n">df</span><span class="p">.</span><span class="n">TMIN</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>31
</code></pre></div></div>

<p>And, on occasion, it can surpass the daily maximum temperature:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span> <span class="o">&gt;</span> <span class="n">df</span><span class="p">.</span><span class="n">TMAX</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>235
</code></pre></div></div>

<p>This intriguing phenomenon may be attributed to measurement methods and the consideration that TAVG corresponds to an average for the period ending at 2400 UTC rather than local midnight.</p>

<p>Now let’s take a closer look at missing values within our dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="p">(</span><span class="mi">100</span> <span class="o">*</span> <span class="n">df</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">)).</span><span class="n">plot</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">60</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Ratio of missing values per column</span><span class="sh">"</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Column name</span><span class="sh">"</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Ratio (%)</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_16_0.png" alt="output_16_0" />
</p>

<p>We will utilize segments of the existing TAVG data as both training and testing datasets, with the ultimate aim of predicting the absent values.</p>

<h2 id="first-approach--tavg_am-arithmetic-mean-of-tmin-and-tmax">First approach : TAVG_am, arithmetic mean of TMIN and TMAX</h2>

<p>Let’s kick off our analysis by introducing TAVG_am, which represents the <em>arithmetic mean</em> of TMIN and TMAX:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">]</span> <span class="o">+</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">])</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">]].</span><span class="n">plot</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">df_tmp</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">]].</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">"</span><span class="s">any</span><span class="sh">"</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">df_tmp</span><span class="p">[</span><span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span><span class="p">[:,</span> <span class="n">np</span><span class="p">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df_tmp</span><span class="p">[</span><span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span>
<span class="n">lr</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>
<span class="n">lr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="o">-</span><span class="mi">11</span><span class="p">,</span> <span class="mi">36</span>
<span class="n">points</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">points</span><span class="p">,</span> <span class="n">points</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">lr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set_xlim</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set_ylim</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">"</span><span class="s">TAVG, TAVG_am couples</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">y=x</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">Linear regression</span><span class="sh">"</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Correlation between TAVG and TAVG_am</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_18_0.png" alt="output_18_0" />
</p>

<p>As seen in the scatter plot above, there’s a clear correlation between TAVG and TAVG_am. However, we can observe that TAVG_am may underestimate TAVG by around 3 or 4 degrees. To delve deeper into this discrepancy, let’s examine the error distribution between TAVG and TAVG_am:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">diff</span> <span class="o">=</span> <span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span> <span class="o">-</span> <span class="n">df</span><span class="p">.</span><span class="n">TAVG_am</span><span class="p">).</span><span class="nf">dropna</span><span class="p">()</span>
<span class="n">avg</span> <span class="o">=</span> <span class="n">diff</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">std</span> <span class="o">=</span> <span class="n">diff</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">diff</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="nf">hist</span><span class="p">(</span><span class="n">bins</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">avg</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">avg</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">avg</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">std</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">"</span><span class="s">Distribution</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">$</span><span class="se">\\</span><span class="s">bar{x}$</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">$</span><span class="se">\\</span><span class="s">bar{x} \pm 2 \sigma$</span><span class="sh">"</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Distribution of the error of TAVG_am</span><span class="sh">"</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">TAVG - TAVG_am</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_20_0.png" alt="output_20_0" />
</p>

<h2 id="model-evaluation">Model evaluation</h2>

<p>In order to assess the performance of our model, we’ve defined a convenient evaluation function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">False</span><span class="p">):</span>
    <span class="n">d</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">d</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean_absolute_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
    <span class="n">d</span><span class="p">[</span><span class="sh">"</span><span class="s">rmse</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="nf">mean_squared_error</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">squared</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">return_score</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">d</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span>
            <span class="sa">f</span><span class="sh">'</span><span class="s">Mean absolute error : </span><span class="si">{</span><span class="n">d</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">]</span><span class="si">:</span><span class="mf">8.4</span><span class="n">f</span><span class="si">}</span><span class="s">, Mean squared error : </span><span class="si">{</span><span class="n">d</span><span class="p">[</span><span class="sh">"</span><span class="s">rmse</span><span class="sh">"</span><span class="p">]</span><span class="si">:</span><span class="mf">8.4</span><span class="n">f</span><span class="si">}</span><span class="sh">'</span>
        <span class="p">)</span>
</code></pre></div></div>

<p>This function computes two important metrics:</p>

<ul>
  <li>Mean Absolute Error (MAE)</li>
  <li>Root Mean Squared Error (RMSE)</li>
</ul>

<p>Now, let’s apply this evaluation function to our model predictions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">isna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG_am</span><span class="p">.</span><span class="nf">isna</span><span class="p">(),</span> <span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">isna</span><span class="p">()</span> <span class="o">&amp;</span> <span class="o">~</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG_am</span><span class="p">.</span><span class="nf">isna</span><span class="p">(),</span> <span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.9098, Mean squared error :   1.2088
</code></pre></div></div>

<p>This gives us an idea of the baseline score, which we are going to improve.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># cleanup: remove the temporary TAVG_am column
</span><span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="feature-engineering">Feature engineering</h2>

<p>Let’s add the following features to the dataset:</p>

<ul>
  <li><strong>Cyclic time data encoding</strong></li>
  <li><strong>Diurnal Temperature Range (DTR)</strong></li>
  <li><strong>Daylight length</strong></li>
  <li><strong>TMIN and TMAX delta with adjacent days</strong></li>
</ul>

<h3 id="temporal-features">Temporal features</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">year</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">month</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">month</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">dayofyear</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">].</span><span class="n">dt</span><span class="p">.</span><span class="n">dayofyear</span>
<span class="n">df</span><span class="p">.</span><span class="nf">set_index</span><span class="p">(</span><span class="sh">"</span><span class="s">DATE</span><span class="sh">"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">head</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PRCP</th>
      <th>TAVG</th>
      <th>TMIN</th>
      <th>TMAX</th>
      <th>year</th>
      <th>month</th>
      <th>dayofyear</th>
    </tr>
    <tr>
      <th>DATE</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1920-09-01</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>8.8</td>
      <td>19.7</td>
      <td>1920</td>
      <td>9</td>
      <td>245</td>
    </tr>
    <tr>
      <th>1920-09-02</th>
      <td>0.0</td>
      <td>NaN</td>
      <td>9.1</td>
      <td>20.1</td>
      <td>1920</td>
      <td>9</td>
      <td>246</td>
    </tr>
    <tr>
      <th>1920-09-03</th>
      <td>1.5</td>
      <td>NaN</td>
      <td>9.3</td>
      <td>16.8</td>
      <td>1920</td>
      <td>9</td>
      <td>247</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">daycountinyear</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Timestamp</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">31</span><span class="p">).</span><span class="n">dayofyear</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">sin_encoded_year</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sin</span><span class="p">(</span>
    <span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">dayofyear</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">daycountinyear</span><span class="sh">"</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">cos_encoded_year</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">cos</span><span class="p">(</span>
    <span class="mf">2.0</span> <span class="o">*</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span> <span class="o">*</span> <span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">dayofyear</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">daycountinyear</span><span class="sh">"</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">([</span><span class="sh">"</span><span class="s">year</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">daycountinyear</span><span class="sh">"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ax</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">2020</span><span class="sh">"</span><span class="p">:</span><span class="sh">"</span><span class="s">2020</span><span class="sh">"</span><span class="p">][[</span><span class="sh">"</span><span class="s">sin_encoded_year</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">cos_encoded_year</span><span class="sh">"</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Cyclical encoded day-of-year</span><span class="sh">"</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Day-of-year</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_29_0.png" alt="output_29_0" />
</p>

<p>Radial basis functions:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rbf</span> <span class="o">=</span> <span class="nc">RepeatingBasisFunction</span><span class="p">(</span>
    <span class="n">n_periods</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">column</span><span class="o">=</span><span class="sh">"</span><span class="s">dayofyear</span><span class="sh">"</span><span class="p">,</span> <span class="n">input_range</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">366</span><span class="p">),</span> <span class="n">remainder</span><span class="o">=</span><span class="sh">"</span><span class="s">drop</span><span class="sh">"</span>
<span class="p">)</span>
<span class="n">rbf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
<span class="n">RBFs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">rbf</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="n">RBFs</span> <span class="o">=</span> <span class="n">RBFs</span><span class="p">.</span><span class="nf">add_prefix</span><span class="p">(</span><span class="sh">"</span><span class="s">rbf_</span><span class="sh">"</span><span class="p">)</span>
<span class="n">axs</span> <span class="o">=</span> <span class="n">RBFs</span><span class="p">[:</span><span class="mi">400</span><span class="p">].</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">subplots</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">),</span>
    <span class="n">sharex</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Radial Basis Functions</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">rot</span><span class="o">=</span><span class="mi">90</span><span class="p">,</span>
<span class="p">)</span>
<span class="k">for</span> <span class="n">ax</span> <span class="ow">in</span> <span class="n">axs</span><span class="p">:</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">yaxis</span><span class="p">.</span><span class="nf">set_tick_params</span><span class="p">(</span><span class="n">labelleft</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_31_0.png" alt="output_31_0" />
</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">((</span><span class="n">df</span><span class="p">,</span> <span class="n">RBFs</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="temperature-ranges-deltas-with-previous-and-next-days">Temperature ranges, deltas with previous and next days</h3>

<p>Daily temperature range:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">DTR</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">]</span>
</code></pre></div></div>

<p>TMIN and TMAX deltas with previous and next days:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_day_before</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_day_before</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_day_after</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_day_after</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">].</span><span class="nf">shift</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_delta_db</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_day_before</span><span class="sh">"</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_delta_db</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_day_before</span><span class="sh">"</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_delta_da</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX_day_after</span><span class="sh">"</span><span class="p">]</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_delta_da</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">]</span> <span class="o">-</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN_day_after</span><span class="sh">"</span><span class="p">]</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span>
    <span class="p">[</span><span class="sh">"</span><span class="s">TMIN_day_before</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMAX_day_before</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMIN_day_after</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMAX_day_after</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<h3 id="daytime-length">Daytime length</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">observer</span> <span class="o">=</span> <span class="nc">Observer</span><span class="p">(</span><span class="n">latitude</span><span class="o">=</span><span class="n">station</span><span class="p">.</span><span class="n">LATITUDE</span><span class="p">,</span> <span class="n">longitude</span><span class="o">=</span><span class="n">station</span><span class="p">.</span><span class="n">LONGITUDE</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">compute_daytime</span><span class="p">(</span><span class="n">date</span><span class="p">):</span>
    <span class="n">sr</span><span class="p">,</span> <span class="n">ss</span> <span class="o">=</span> <span class="nf">daylight</span><span class="p">(</span><span class="n">observer</span><span class="p">,</span> <span class="n">date</span><span class="o">=</span><span class="n">date</span><span class="p">)</span>
    <span class="nf">return </span><span class="p">(</span><span class="n">ss</span> <span class="o">-</span> <span class="n">sr</span><span class="p">).</span><span class="nf">total_seconds</span><span class="p">()</span>


<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">datetime</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">index</span>
<span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">daytime</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">"</span><span class="s">datetime</span><span class="sh">"</span><span class="p">].</span><span class="nf">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">d</span><span class="p">:</span> <span class="nf">compute_daytime</span><span class="p">(</span><span class="n">d</span><span class="p">))</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">datetime</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="traintest-split">Train/test split</h2>

<p>In this section, we split our dataset into two distinct sets – the training set and the testing set. First, we identify our target variable, which is what we want to predict – TAVG. We also define our features, which are the input variables used to make predictions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">target</span> <span class="o">=</span> <span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span>
<span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="n">c</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="k">if</span> <span class="n">c</span> <span class="o">!=</span> <span class="n">target</span><span class="p">]</span>
<span class="n">features</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['PRCP',
 'TMIN',
 'TMAX',
 'month',
 'dayofyear',
 'sin_encoded_year',
 'cos_encoded_year',
 'rbf_0',
 'rbf_1',
 'rbf_2',
 'rbf_3',
 'rbf_4',
 'rbf_5',
 'DTR',
 'TMAX_delta_db',
 'TMIN_delta_db',
 'TMAX_delta_da',
 'TMIN_delta_da',
 'daytime']
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="o">~</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">isna</span><span class="p">()].</span><span class="nf">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">.</span><span class="nf">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="sh">"</span><span class="s">any</span><span class="sh">"</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="n">features</span><span class="p">].</span><span class="nf">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span> <span class="n">dataset</span><span class="p">[</span><span class="n">target</span><span class="p">].</span><span class="nf">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="baseline--arithmetic-mean">Baseline : arithmetic mean</h2>

<p>In this section, we establish a simple baseline model for predicting the average temperature with the arithmetic mean:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">BaselineModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X_test</span><span class="p">):</span>
        <span class="k">if</span> <span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span> <span class="ow">in</span> <span class="n">X_test</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">TAVG_am</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="p">(</span><span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span> <span class="o">+</span> <span class="n">X_test</span><span class="p">[</span><span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">].</span><span class="n">values</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">baseline</span> <span class="o">=</span> <span class="nc">BaselineModel</span><span class="p">()</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">baseline</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">()</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)).</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">baseline</span><span class="sh">"</span><span class="p">).</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="ridge">Ridge</h2>

<p>Now we introduce our first predictive model: Ridge Regression. Ridge Regression is a linear regression variant that is particularly useful when dealing with multicollinearity in the data.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">ridge_reg</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">scaler</span><span class="sh">"</span><span class="p">,</span> <span class="nc">StandardScaler</span><span class="p">()),</span>
        <span class="p">(</span><span class="sh">"</span><span class="s">ridge</span><span class="sh">"</span><span class="p">,</span> <span class="nc">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)),</span>
    <span class="p">]</span>
<span class="p">)</span>
<span class="n">ridge_reg</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">ridge_reg</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)).</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">ridge</span><span class="sh">"</span><span class="p">).</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>0.740136</td>
      <td>0.984712</td>
    </tr>
  </tbody>
</table>
</div>

<p>Also, let’s plot the feature importance and drop the least important features:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fi</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">:</span> <span class="n">ridge_reg</span><span class="p">[</span><span class="sh">"</span><span class="s">ridge</span><span class="sh">"</span><span class="p">].</span><span class="n">coef_</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fi</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fi</span><span class="p">.</span><span class="n">plot</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">invert_yaxis</span><span class="p">()</span>
</code></pre></div></div>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/output_49_0.png" alt="output_49_0" />
</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">dayofyear</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">month</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMIN_delta_db</span><span class="sh">"</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">drop_features</span><span class="p">:</span>
    <span class="n">features</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="decisiontreeregressor">DecisionTreeRegressor</h2>

<p>Let’s explore the Decision Tree Regressor, a non-linear regression model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dtr</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>
<span class="n">dtr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dtr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.9473, Mean squared error :   1.2625
</code></pre></div></div>

<p>Next, we experiment with different tree depths ranging from 2 to 20. For each depth, we evaluate the model’s performance on both the training and testing data, recording the MAE scores for each.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mae_train_score</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">mae_test_score</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">md</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">21</span><span class="p">):</span>
    <span class="n">dtr</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">md</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>
    <span class="n">dtr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dtr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
    <span class="n">d_train</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">mae_train_score</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">d_train</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">])</span>

    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">dtr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
    <span class="n">d_test</span> <span class="o">=</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="n">mae_test_score</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">d_test</span><span class="p">[</span><span class="sh">"</span><span class="s">mae</span><span class="sh">"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> <span class="n">mae_train_score</span><span class="p">)</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="nf">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">21</span><span class="p">),</span> <span class="n">mae_test_score</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">gca</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">([</span><span class="sh">"</span><span class="s">train</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">test</span><span class="sh">"</span><span class="p">])</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Train/test error vs max_depth</span><span class="sh">"</span><span class="p">,</span> <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">max_depth</span><span class="sh">"</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="sh">"</span><span class="s">MAE</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_54_0.png" alt="output_54_0" />
</p>

<p>It seems like <code class="language-plaintext highlighter-rouge">max_depth</code>=8 is the best one:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dtr</span> <span class="o">=</span> <span class="nc">DecisionTreeRegressor</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>
<span class="n">dtr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">dtr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="p">.</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">decision tree</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>0.740136</td>
      <td>0.984712</td>
    </tr>
    <tr>
      <th>decision tree</th>
      <td>0.782112</td>
      <td>1.049301</td>
    </tr>
  </tbody>
</table>
</div>

<p>Now we analyze feature importance and remove some useless features from the dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fi</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">:</span> <span class="n">dtr</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fi</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fi</span><span class="p">[:</span><span class="mi">30</span><span class="p">].</span><span class="n">plot</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">logx</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">invert_yaxis</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Decision tree feature importance</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Importance (Log scale)</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Feature</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/output_57_0.png" alt="output_57_0" />
</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">rbf_2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">rbf_4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">sin_encoded_year</span><span class="sh">"</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">drop_features</span><span class="p">:</span>
    <span class="n">features</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="randomforestregressor">RandomForestRegressor</h2>

<p>From scikit-learn’s <a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">documentation</a>:</p>

<blockquote>
  <p>A random forest is a meta estimator that fits a number of classifying decision trees on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.</p>
</blockquote>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rfr</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span>
    <span class="n">n_estimators</span><span class="o">=</span><span class="mi">250</span><span class="p">,</span>
    <span class="n">max_depth</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span>
    <span class="n">min_samples_split</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
    <span class="n">max_features</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">12</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">rfr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">rfr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.6746, Mean squared error :   0.9102
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="p">.</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">random forest</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>0.740136</td>
      <td>0.984712</td>
    </tr>
    <tr>
      <th>decision tree</th>
      <td>0.782112</td>
      <td>1.049301</td>
    </tr>
    <tr>
      <th>random forest</th>
      <td>0.674629</td>
      <td>0.910177</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fi</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="p">{</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">:</span> <span class="n">rfr</span><span class="p">.</span><span class="n">feature_importances_</span><span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="n">X_train</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">fi</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">"</span><span class="s">importance</span><span class="sh">"</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fi</span><span class="p">[:</span><span class="mi">25</span><span class="p">].</span><span class="n">plot</span><span class="p">.</span><span class="nf">barh</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">logx</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">legend</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">invert_yaxis</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="p">.</span><span class="nf">set</span><span class="p">(</span>
    <span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">Random forest feature importance</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">xlabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Importance (Log scale)</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">ylabel</span><span class="o">=</span><span class="sh">"</span><span class="s">Feature</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/output_63_0.png" alt="output_63_0" />
</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">drop_features</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">rbf_5</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">rbf_1</span><span class="sh">"</span><span class="p">]</span>
<span class="n">X_train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X_test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">X</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">drop_features</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">drop_features</span><span class="p">:</span>
    <span class="n">features</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="histgradientboostingregressor">HistGradientBoostingRegressor</h2>

<p>Next we use the <em>HistGradientBoostingRegressor</em>, a gradient boosting algorithm that’s known for its efficiency and performance:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hgbr</span> <span class="o">=</span> <span class="nc">HistGradientBoostingRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">)</span>
<span class="n">hgbr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">hgbr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.6692, Mean squared error :   0.9037
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="p">.</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">hist gradient boosting</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>0.740136</td>
      <td>0.984712</td>
    </tr>
    <tr>
      <th>decision tree</th>
      <td>0.782112</td>
      <td>1.049301</td>
    </tr>
    <tr>
      <th>random forest</th>
      <td>0.674629</td>
      <td>0.910177</td>
    </tr>
    <tr>
      <th>hist gradient boosting</th>
      <td>0.669222</td>
      <td>0.903695</td>
    </tr>
  </tbody>
</table>
</div>

<p>The default values are giving good results, but let’s try to perfom some hyperparameter optimization with <a href="https://optuna.org/">Optuna</a>. The optimization process aims to find the best combination of hyperparameters that results in a model with improved predictive performance.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">FIXED_PARAMS</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">squared_error</span><span class="sh">"</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">monotonic_cst</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span><span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">validation_fraction</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.15</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">n_iter_no_change</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">early_stopping</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">FIXED_PARAMS</span><span class="p">[</span><span class="sh">"</span><span class="s">random_state</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">RS</span>


<span class="k">class</span> <span class="nc">Objective</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">fixed_params</span><span class="o">=</span><span class="n">FIXED_PARAMS</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">X</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">self</span><span class="p">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">self</span><span class="p">.</span><span class="n">fixed_params</span> <span class="o">=</span> <span class="n">fixed_params</span>

    <span class="k">def</span> <span class="nf">__call__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">trial</span><span class="p">):</span>
        <span class="n">learning_rate</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_float</span><span class="p">(</span><span class="sh">"</span><span class="s">learning_rate</span><span class="sh">"</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">max_iter</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">"</span><span class="s">max_iter</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">150</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">250</span><span class="p">])</span>
        <span class="n">max_leaf_nodes</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">max_leaf_nodes</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="mi">26</span><span class="p">,</span> <span class="mi">31</span><span class="p">,</span> <span class="mi">36</span><span class="p">,</span> <span class="mi">41</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">max_depth</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">"</span><span class="s">max_depth</span><span class="sh">"</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
        <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">min_samples_leaf</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">30</span><span class="p">]</span>
        <span class="p">)</span>
        <span class="n">l2_regularization</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_float</span><span class="p">(</span>
            <span class="sh">"</span><span class="s">l2_regularization</span><span class="sh">"</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="mf">1e-1</span><span class="p">,</span> <span class="n">log</span><span class="o">=</span><span class="bp">True</span>
        <span class="p">)</span>
        <span class="n">max_bins</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">"</span><span class="s">max_bins</span><span class="sh">"</span><span class="p">,</span> <span class="p">[</span><span class="mi">205</span><span class="p">,</span> <span class="mi">225</span><span class="p">,</span> <span class="mi">255</span><span class="p">])</span>

        <span class="n">hgbr</span> <span class="o">=</span> <span class="nc">HistGradientBoostingRegressor</span><span class="p">(</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">max_leaf_nodes</span><span class="o">=</span><span class="n">max_leaf_nodes</span><span class="p">,</span>
            <span class="n">max_depth</span><span class="o">=</span><span class="n">max_depth</span><span class="p">,</span>
            <span class="n">min_samples_leaf</span><span class="o">=</span><span class="n">min_samples_leaf</span><span class="p">,</span>
            <span class="n">l2_regularization</span><span class="o">=</span><span class="n">l2_regularization</span><span class="p">,</span>
            <span class="n">max_bins</span><span class="o">=</span><span class="n">max_bins</span><span class="p">,</span>
            <span class="o">**</span><span class="n">self</span><span class="p">.</span><span class="n">fixed_params</span>
        <span class="p">)</span>

        <span class="n">score</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span>
            <span class="n">hgbr</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">X</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">y</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">"</span><span class="s">neg_mean_absolute_error</span><span class="sh">"</span>
        <span class="p">)</span>
        <span class="n">mae</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="n">score</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">mae</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">objective</span> <span class="o">=</span> <span class="nc">Objective</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="nc">NSGAIISampler</span><span class="p">(</span>
    <span class="n">population_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">seed</span><span class="o">=</span><span class="n">RS</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">study</span> <span class="o">=</span> <span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">"</span><span class="s">minimize</span><span class="sh">"</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span>
    <span class="n">objective</span><span class="p">,</span>
    <span class="n">n_trials</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[I 2023-09-06 13:52:45,182] A new study created in memory with name: no-name-d32e6de4-7cae-43d5-8f5e-afe0d72605b9
[I 2023-09-06 13:52:45,989] Trial 0 finished with value: 1.8808348240559607 and parameters: {'learning_rate': 0.025532591774822706, 'max_iter': 50, 'max_leaf_nodes': 36, 'max_depth': 9, 'min_samples_leaf': 15, 'l2_regularization': 0.0012473085120470293, 'max_bins': 225}. Best is trial 0 with value: 
...
[I 2023-09-06 14:01:29,745] Trial 999 finished with value: 0.6788856968370406 and parameters: {'learning_rate': 0.04112414787841993, 'max_iter': 250, 'max_leaf_nodes': 36, 'max_depth': 22, 'min_samples_leaf': 30, 'l2_regularization': 0.0024433893814918765, 'max_bins': 225}. Best is trial 868 with value: 0.6764808748435326.
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hp</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_params</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>
<span class="n">hp</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">FIXED_PARAMS</span><span class="p">)</span>
<span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">hp</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
    <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="n">key</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">20</span><span class="n">s</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">value</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="si">{</span><span class="sh">'</span><span class="s">best objective value</span><span class="sh">'</span><span class="si">:</span><span class="o">&gt;</span><span class="mi">20</span><span class="n">s</span><span class="si">}</span><span class="s"> : </span><span class="si">{</span><span class="n">study</span><span class="p">.</span><span class="n">best_value</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>       learning_rate : 0.04403581826578526
            max_iter : 200
      max_leaf_nodes : 36
           max_depth : 28
    min_samples_leaf : 25
   l2_regularization : 0.017899518645399605
            max_bins : 255
                loss : squared_error
       monotonic_cst : {'TMIN': 1, 'TMAX': 1}
 validation_fraction : 0.15
    n_iter_no_change : 15
      early_stopping : True
        random_state : 124
best objective value : 0.6764808748435326
</code></pre></div></div>

<p>Next we plot the HPO history. We can observe that the minimization process is rapidly reaching a plateau:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">trials</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="nf">trials_dataframe</span><span class="p">()</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">ndarray</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">trials</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">value_min</span> <span class="o">=</span> <span class="mf">1.0e15</span>
<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">trials</span><span class="p">.</span><span class="nf">itertuples</span><span class="p">():</span>
    <span class="n">value_min</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">amin</span><span class="p">([</span><span class="n">value_min</span><span class="p">,</span> <span class="n">row</span><span class="p">.</span><span class="n">value</span><span class="p">])</span>
    <span class="n">score</span><span class="p">[</span><span class="n">row</span><span class="p">.</span><span class="n">number</span><span class="p">]</span> <span class="o">=</span> <span class="n">value_min</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="n">trials</span><span class="p">[</span><span class="sh">"</span><span class="s">best_value</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">score</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">trials</span><span class="p">[[</span><span class="sh">"</span><span class="s">number</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">best_value</span><span class="sh">"</span><span class="p">]].</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">number</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">best_value</span><span class="sh">"</span><span class="p">,</span> <span class="n">logy</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">r</span><span class="sh">"</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Best value</span><span class="sh">"</span>
<span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">trials</span><span class="p">[[</span><span class="sh">"</span><span class="s">number</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">]].</span><span class="n">plot</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span>
    <span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">number</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">value</span><span class="sh">"</span><span class="p">,</span> <span class="n">logy</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">b</span><span class="sh">"</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">Trial value</span><span class="sh">"</span>
<span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="600" src="/img/2023-09-15_01/output_71_0.png" alt="output_71_0" />
</p>

<p>Let’s evaluate our model. Eval on train set:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">kf</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">n_splits</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">RS</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">hgbrs</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">X_train</span><span class="p">):</span>
    <span class="n">hgbr</span> <span class="o">=</span> <span class="nc">HistGradientBoostingRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">hp</span><span class="p">)</span>
    <span class="n">hgbr</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">],</span> <span class="n">y_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_index</span><span class="p">])</span>
    <span class="n">hgbrs</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">hgbr</span><span class="p">)</span>
    <span class="n">y_pred</span><span class="p">[</span><span class="n">test_index</span><span class="p">]</span> <span class="o">=</span> <span class="n">hgbr</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_index</span><span class="p">])</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.6767, Mean squared error :   0.9047
</code></pre></div></div>

<p>Eval on test set:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">X_test</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">hgbrs</span><span class="p">:</span>
    <span class="n">y_pred</span> <span class="o">+=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">hgbrs</span><span class="p">)</span>
<span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Mean absolute error :   0.6673, Mean squared error :   0.9018
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span>
    <span class="p">[</span>
        <span class="n">results</span><span class="p">,</span>
        <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="nf">evaluate</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">return_score</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
        <span class="p">.</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">hist gradient boosting w HPO</span><span class="sh">"</span><span class="p">)</span>
        <span class="p">.</span><span class="n">T</span><span class="p">,</span>
    <span class="p">],</span>
    <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">results</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mae</th>
      <th>rmse</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>baseline</th>
      <td>0.916753</td>
      <td>1.214852</td>
    </tr>
    <tr>
      <th>ridge</th>
      <td>0.740136</td>
      <td>0.984712</td>
    </tr>
    <tr>
      <th>decision tree</th>
      <td>0.782112</td>
      <td>1.049301</td>
    </tr>
    <tr>
      <th>random forest</th>
      <td>0.674629</td>
      <td>0.910177</td>
    </tr>
    <tr>
      <th>hist gradient boosting</th>
      <td>0.669222</td>
      <td>0.903695</td>
    </tr>
    <tr>
      <th>hist gradient boosting w HPO</th>
      <td>0.667300</td>
      <td>0.901843</td>
    </tr>
  </tbody>
</table>
</div>

<p>The final evaluation confirms that our HPO did not really improve the model. It does not always lead to better results…</p>

<h2 id="fill-the-missing-tavg-values">Fill the missing TAVG values</h2>

<p>Low it’s time to handle the missing TAVG values through prediction and imputation, ensuring that the dataset is ready for further analysis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_mv</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">isna</span><span class="p">()][</span><span class="n">features</span><span class="p">]</span>  <span class="c1"># dataset with missing TAVG values
</span><span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">X_mv</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">float64</span><span class="p">)</span>
<span class="k">for</span> <span class="n">model</span> <span class="ow">in</span> <span class="n">hgbrs</span><span class="p">:</span>
    <span class="n">y_pred</span> <span class="o">+=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_mv</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">/=</span> <span class="nf">len</span><span class="p">(</span><span class="n">hgbrs</span><span class="p">)</span>
<span class="n">TAVG_pred</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">X_mv</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">TAVG_pred</span><span class="sh">"</span><span class="p">])</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">((</span><span class="n">df</span><span class="p">,</span> <span class="n">TAVG_pred</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="n">TAVG</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">TAVG_pred</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">"</span><span class="s">TAVG_pred</span><span class="sh">"</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="sh">"</span><span class="s">PRCP</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TAVG</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMIN</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">TMAX</span><span class="sh">"</span><span class="p">]]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">_</span> <span class="o">=</span> <span class="n">msno</span><span class="p">.</span><span class="nf">matrix</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</code></pre></div></div>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/output_79_0.png" alt="output_79_0" />
</p>

<p>Let’s save the updated dataset in our favorite file format:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="nf">to_parquet</span><span class="p">(</span><span class="sh">"</span><span class="s">./lyon_historical_temperatures.parquet</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div>
<p>In the following section we perform an analysis of the temperature anomalies during meteorological summer months with respect to a historical average. This will make use of the reconstructed variable TAVG, by taking the average of this mean daily temperature over the 3 warmest months of the year.</p>

<h2 id="meteorological-summer-months-temperature-anomalies">Meteorological Summer months temperature anomalies</h2>

<p>We are going to analyzing temperature anomalies during meteorological summer months (June, July, August) in Lyon – Saint-Exupéry Airport, France, compared to a historical average:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">start</span><span class="p">,</span> <span class="n">end</span> <span class="o">=</span> <span class="sh">"</span><span class="s">1920</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">1980</span><span class="sh">"</span>

<span class="n">df_summer</span> <span class="o">=</span> <span class="n">T_month</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">T_month</span><span class="p">.</span><span class="n">month</span><span class="p">.</span><span class="nf">isin</span><span class="p">([</span><span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">])].</span><span class="n">TAVG</span><span class="p">.</span><span class="nf">resample</span><span class="p">(</span><span class="sh">"</span><span class="s">Y</span><span class="sh">"</span><span class="p">).</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">t_summer</span> <span class="o">=</span> <span class="n">df_summer</span><span class="p">[</span><span class="n">start</span><span class="p">:</span><span class="n">end</span><span class="p">].</span><span class="nf">mean</span><span class="p">()</span>

<span class="n">anomaly</span> <span class="o">=</span> <span class="p">(</span><span class="n">df_summer</span> <span class="o">-</span> <span class="n">t_summer</span><span class="p">).</span><span class="nf">copy</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">anomaly</span><span class="sh">"</span><span class="p">)</span>
<span class="n">anomaly</span><span class="p">[</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="nf">astype</span><span class="p">(</span><span class="nb">str</span><span class="p">)</span>
<span class="n">anomaly</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">anomaly</span><span class="p">[</span><span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">].</span><span class="nb">str</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="sh">"</span><span class="s">0</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">label</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="sh">""</span>
<span class="n">rw</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">.</span><span class="n">anomaly</span><span class="p">.</span><span class="nf">rolling</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">center</span><span class="o">=</span><span class="bp">True</span><span class="p">).</span><span class="nf">mean</span><span class="p">().</span><span class="nf">to_frame</span><span class="p">(</span><span class="sh">"</span><span class="s">window</span><span class="sh">"</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">FS</span><span class="p">)</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">anomaly</span><span class="p">[</span><span class="n">start</span><span class="p">:].</span><span class="n">anomaly</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">colors</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="sh">"</span><span class="s">dodgerblue</span><span class="sh">"</span><span class="p">]</span> <span class="o">*</span> <span class="nf">len</span><span class="p">(</span><span class="n">anomaly</span><span class="p">[</span><span class="n">start</span><span class="p">:]))</span>
<span class="n">colors</span><span class="p">[</span><span class="n">mask</span><span class="p">.</span><span class="n">values</span><span class="p">]</span> <span class="o">=</span> <span class="sh">"</span><span class="s">tomato</span><span class="sh">"</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">anomaly</span><span class="p">[</span><span class="n">start</span><span class="p">:].</span><span class="n">index</span><span class="p">.</span><span class="n">year</span><span class="p">,</span> <span class="n">anomaly</span><span class="p">[</span><span class="n">start</span><span class="p">:].</span><span class="n">anomaly</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">colors</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span>
    <span class="n">rw</span><span class="p">[</span><span class="n">start</span><span class="p">:].</span><span class="n">index</span><span class="p">.</span><span class="n">year</span><span class="p">.</span><span class="nf">tolist</span><span class="p">(),</span>
    <span class="n">rw</span><span class="p">[</span><span class="n">start</span><span class="p">:].</span><span class="n">window</span><span class="p">.</span><span class="n">values</span><span class="p">,</span>
    <span class="sh">"</span><span class="s">k</span><span class="sh">"</span><span class="p">,</span>
    <span class="n">linewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span>
    <span class="n">label</span><span class="o">=</span><span class="sh">"</span><span class="s">10-year moving average</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nf">int</span><span class="p">(</span><span class="n">end</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">grey</span><span class="sh">"</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">Date</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_ylabel</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">Degrees (°C) +/- from </span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">end</span><span class="si">}</span><span class="s"> average</span><span class="sh">"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span>
    <span class="sa">f</span><span class="sh">"</span><span class="s">Meteorological summer temperature anomalies</span><span class="se">\n</span><span class="s"> in Lyon – Saint-Exupéry Airport – France </span><span class="se">\n</span><span class="s">w.r.t </span><span class="si">{</span><span class="n">start</span><span class="si">}</span><span class="s">-</span><span class="si">{</span><span class="n">end</span><span class="si">}</span><span class="s"> mean</span><span class="sh">"</span>
<span class="p">);</span>
</code></pre></div></div>

<p align="center">
  <img width="1000" src="/img/2023-09-15_01/output_86_0.png" alt="output_86_0" />
</p>

<h2 id="reference">Reference</h2>

<p>[1] Bernhardt, J., <em>“A comparison of daily temperature-averaging methods: Uncertainties, spatial variability, and societal implications”</em>, PhDT, Pennsylvania State University, 2016.</p>

<div id="disqus_thread"></div>
<script>

/**
*  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
*  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
/*
var disqus_config = function () {
this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
};
*/
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://aetperf-github-io-1.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>

<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
